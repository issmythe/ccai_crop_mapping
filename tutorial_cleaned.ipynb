{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/issmythe/ccai_crop_mapping/blob/main/tutorial_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ2Sgm2z9Opu"
      },
      "source": [
        "# OpenMapFlow Tutorial\n",
        "\n",
        "### Sections\n",
        "1. Installing OpenMapFlow\n",
        "2. Exploring labeled earth observation data\n",
        "3. Training a model\n",
        "4. Doing inference over small region\n",
        "5. Deploying of best model\n",
        "\n",
        "### Prerequisites:\n",
        "- Github account\n",
        "- Github access token (obtained [here](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token))\n",
        "- Forked OpenMapFlow repository\n",
        "- Basic Python knowledge  \n",
        "\n",
        "### Editable Google Doc for Q&A:\n",
        "https://docs.google.com/document/d/1Kp6MphER1G5tdLYeAzl4n19S10TweIxiYT64rXsjKm4/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnb3NmfxSQyo"
      },
      "source": [
        "## 1. Clone Github repo and install OpenMapFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5AZyaN_8dUKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug7hI6g7Wu3f"
      },
      "outputs": [],
      "source": [
        "!pip install \"ipywidgets>=7,<8\" -q # https://github.com/googlecolab/colabtools/issues/3020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxD8Zbzr8lyu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Git credentials\n",
        "from ipywidgets import HTML, Password, Text, Textarea, VBox\n",
        "inputs = [\n",
        "      Password(description=\"Github Token:\"),\n",
        "      Text(description='Github Email:'),\n",
        "      Text(description='Github User:'),\n",
        "]\n",
        "VBox(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16CaMAzNxokf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone directory\n",
        "token = inputs[0].value\n",
        "email = inputs[1].value\n",
        "username = inputs[2].value\n",
        "\n",
        "github_url_input = Textarea(value=f'https://github.com/{username}/openmapflow.git')\n",
        "VBox([HTML(value=\"<b>Github Clone URL</b>\"), github_url_input])\n",
        "\n",
        "! git clone -q https://$token@github.com/nasaharvest/openmapflow.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mg8UBJ_HP6Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdFlxgOX9Mit",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Config\n",
        "from pathlib import Path\n",
        "\n",
        "github_url = github_url_input.value\n",
        "project_name = \"crop-mask-example\" # maize-example\n",
        "country_name = \"Togo\" # Kenya\n",
        "\n",
        "for input_value in [token, email, username, github_url]:\n",
        "  if input_value.strip() == \"\":\n",
        "    raise ValueError(\"Found input with blank value.\")\n",
        "\n",
        "path_to_project = f\"{Path(github_url).stem}/{project_name}\"\n",
        "\n",
        "!git config --global user.email $username\n",
        "!git config --global user.name $email\n",
        "!git clone {github_url.replace(\"https://\", f\"https://{username}:{token}@\")}\n",
        "\n",
        "%cd {path_to_project}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installs\n",
        "!pip install openmapflow[all] -q &> /dev/null\n",
        "!pip install dvc[gs] cmocean -q &> /dev/null"
      ],
      "metadata": {
        "id": "AK7eXnZEXb4_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download GDAL\n",
        "%%shell\n",
        "GDAL_VERSION=\"3.6.4+dfsg-1~jammy0\"\n",
        "add-apt-repository -y ppa:ubuntugis/ubuntugis-unstable &> /dev/null\n",
        "apt-get -qq update &> /dev/null\n",
        "apt-get -qq install python3-gdal=$GDAL_VERSION gdal-bin=$GDAL_VERSION libgdal-dev=$GDAL_VERSION &> /dev/null"
      ],
      "metadata": {
        "id": "NGv4CE0zXLxj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckKKdRZW-06Q"
      },
      "outputs": [],
      "source": [
        "# CLI\n",
        "!openmapflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JTyoKBeBNt3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT5oQHkeBDIg"
      },
      "source": [
        "## 2. Exploring labeled earth observation data ðŸ›°ï¸\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "5YmEZeoxG77r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhzRYzMNOiNV"
      },
      "outputs": [],
      "source": [
        "# A Google Cloud Account is required to access the data\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR9cC92EIKC6"
      },
      "outputs": [],
      "source": [
        "# Pull in data already available\n",
        "! dvc pull &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tc1Hblc-7vf"
      },
      "outputs": [],
      "source": [
        "# See report of data already available\n",
        "! openmapflow datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzHcMQV1S0pS"
      },
      "source": [
        "### Exploring labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swxLRI8B_4iY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports + read data\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from datasets import datasets, label_col\n",
        "from openmapflow.constants import LAT, LON, DATASET, SUBSET\n",
        "\n",
        "df = pd.concat([d.load_df(to_np=True) for d in datasets[:1]]) # Global only"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObzeO-2EHWEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zoi8t0A0YfsM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Convert pandas dataframe to geopandas dataframe\n",
        "gdf = gpd.GeoDataFrame(df)\n",
        "gdf[\"geometry\"] = [Point(xy) for xy in zip(gdf[LON], gdf[LAT])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLd5xf29ZHdm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plot labels\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "ax = world.plot(figsize=(20,20), facecolor=\"lightgray\")\n",
        "ax.set_title(\"Label Locations\")\n",
        "ax.axis('off')\n",
        "gdf.plot(\n",
        "    ax=ax,\n",
        "    marker='o',\n",
        "    categorical=True,\n",
        "    markersize=1,\n",
        "    column=DATASET,\n",
        "    legend=True,\n",
        "    legend_kwds={'loc': 'lower left'});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSzLeUIxPp1i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity with Mexico"
      ],
      "metadata": {
        "id": "3uBwIbCiU67j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "f4kZs3fQdPfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read country shapefile and make dataframes\n",
        "countries = gpd.read_file('/content/world_adm.geojson')\n",
        "gdf.crs = countries.crs # NASA Harvest data doesn't have a CRS but this seems to work as expected\n",
        "gdf_lab = countries[['name', 'geometry']].sjoin(gdf, how='inner', predicate='intersects')\n",
        "gdf_lab = gdf_lab.drop('geometry', axis=1)\n",
        "\n",
        "mex_train = pd.DataFrame(gdf_lab[gdf_lab['name'] == 'Mexico'])\n",
        "\n",
        "np.random.seed(123)\n",
        "mex_train = mex_train.sample(frac=1).reset_index(drop=True)\n",
        "mex_train.loc[mex_train.index > int(len(mex_train) * 0.7), 'subset'] = 'validation'\n",
        "mex_train.loc[mex_train.index > int(len(mex_train) * 0.9), 'subset'] = 'testing'\n",
        "\n",
        "df = pd.concat([gdf_lab[gdf_lab['name'] != 'Mexico'], mex_train])\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f8pyQB8dGL4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get principal components\n",
        "ss = StandardScaler()\n",
        "\n",
        "df['pca_data'] = df['eo_data'].apply(np.ravel)\n",
        "df['pca_data'] = ss.fit_transform(np.stack(df['pca_data'])).tolist()\n",
        "\n",
        "pca = PCA(n_components=10)\n",
        "pcs = pca.fit_transform(np.stack(df['pca_data']))\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "for i in range(5):\n",
        "    df[f'pc{i}'] = pcs[:, i]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Fl5aMYI3GL4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Map principal component values\n",
        "col = 'pc2'\n",
        "vmin=df[col].quantile(0.01)\n",
        "vmax=df[col].quantile(0.99)\n",
        "\n",
        "sns.set_style('white')\n",
        "f, ax = plt.subplots(figsize=[18, 9])\n",
        "ax.set_axis_off()\n",
        "\n",
        "countries.plot(color='none', edgecolor='darkgray', ax=ax)\n",
        "plot_df.plot(column=col, vmin=vmin, vmax=vmax, markersize=2, cmap='viridis', ax=ax)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Mh1ymr3yGL4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Filter global training data based on Mexico PC values\n",
        "mex = df.loc[df['name'] == 'Mexico']\n",
        "filtered = df.loc[df['name'] != 'Mexico'].copy()\n",
        "print(len(filtered))\n",
        "filtered['inc1'] = 1 # All PCs within central 98% of Mexico data\n",
        "filtered['inc5'] = 1 # All PCs within central 90% of Mexico data\n",
        "\n",
        "for i in range(5):\n",
        "    filtered.loc[filtered[f'pc{i}'] < mex[f'pc{i}'].quantile(0.01), 'inc1'] = 0\n",
        "    filtered.loc[filtered[f'pc{i}'] < mex[f'pc{i}'].quantile(0.05), 'inc5'] = 0\n",
        "\n",
        "    filtered.loc[filtered[f'pc{i}'] > mex[f'pc{i}'].quantile(0.99), 'inc1'] = 0\n",
        "    filtered.loc[filtered[f'pc{i}'] > mex[f'pc{i}'].quantile(0.95), 'inc5'] = 0\n",
        "\n",
        "    print(filtered['inc1'].sum(), filtered['inc5'].sum())\n",
        "\n",
        "# Expect to have n = 14639 for middle 98%, n = 7656 for middle 90%\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6SVrSmLQU_E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Map which locations are included in filtered dataset\n",
        "plot_df = gpd.GeoDataFrame(filtered)\n",
        "plot_df['geometry'] = [Point(xy) for xy in zip(plot_df[LON], plot_df[LAT])]\n",
        "\n",
        "sns.set_style('white')\n",
        "f, ax = plt.subplots(figsize=[18, 9])\n",
        "ax.set_axis_off()\n",
        "\n",
        "countries.plot(color='none', edgecolor='darkgray', ax=ax)\n",
        "plot_df.plot(markersize=2, ax=ax, color='gray')\n",
        "plot_df[plot_df['inc1'] == 1].plot(markersize=2, ax=ax, color='blue')\n",
        "plot_df[plot_df['inc5'] == 1].plot(markersize=2, ax=ax, color='red')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dt9mW1GiRbSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pnmUitwyGOtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTxkzHh6BreD"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "3PEtWue83OWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set metaparams\n",
        "model_name = 'm1'\n",
        "\n",
        "start_month = 'February'\n",
        "input_months = 12\n",
        "batch_size = 32\n",
        "upsample_minority_ratio = 0.5\n",
        "lr = 1e-4\n",
        "num_epochs = 25\n"
      ],
      "metadata": {
        "id": "0AuF_K7ENufu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import torch\n",
        "import yaml\n",
        "from datasets import datasets, label_col\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "from tsai.models.TransformerModel import TransformerModel\n",
        "\n",
        "from openmapflow.bands import BANDS_MAX\n",
        "from openmapflow.constants import SUBSET\n",
        "from openmapflow.pytorch_dataset import PyTorchDataset\n",
        "from openmapflow.train_utils import (\n",
        "    generate_model_name,\n",
        "    get_x_y,\n",
        "    model_path_from_name,\n",
        "    upsample_df,\n",
        ")\n",
        "from openmapflow.utils import tqdm\n",
        "\n",
        "try:\n",
        "    import google.colab  # noqa\n",
        "\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)  # TorchScript throws excessive warnings"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z6qY4yVbNpBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Overwrite get_x_y\n",
        "from typing import List, Tuple\n",
        "from openmapflow.constants import CLASS_PROB, EO_DATA, MONTHS\n",
        "from openmapflow.utils import str_to_np\n",
        "\n",
        "def get_x_y(\n",
        "    df: pd.DataFrame,\n",
        "    label_col: str = CLASS_PROB,\n",
        "    start_month: str = \"February\",\n",
        "    input_months: int = 12,\n",
        ") -> Tuple[List[np.ndarray], List[float]]:\n",
        "    \"\"\"Get the X and y data from a dataframe.\"\"\"\n",
        "    i = MONTHS.index(start_month)\n",
        "\n",
        "    def to_numpy(x: str):\n",
        "        if type(x) == str:\n",
        "            x = str_to_np(x)\n",
        "        return x[i : i + input_months, :]  # noqa\n",
        "\n",
        "    tqdm.pandas()\n",
        "    return df[EO_DATA].progress_apply(to_numpy).to_list(), df[label_col].to_list()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N4vKNSpaQkTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get country boundaries\n",
        "countries = gpd.read_file('/content/world_adm.geojson')\n",
        "gdf_lab = countries[['name', 'geometry']].sjoin(gdf, how='inner', predicate='intersects')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EJEzAa6FDxFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmLfSZkobDyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data setup\n",
        "keep_cols = ['name', 'lon', 'lat', 'class_probability', 'subset', 'eo_data']\n",
        "gdf_lab = gdf_lab.loc[gdf_lab['name'] != 'Mexico', keep_cols]\n",
        "\n",
        "mex_adm1 = gpd.read_file('/content/mex_adm1.geojson').rename({'shapeISO': 'adm1'}, axis=1)\n",
        "mex_gdf = mex_adm1[['adm1', 'geometry']].sjoin(gdf, how='inner', predicate='intersects')\n",
        "mex_gdf = mex_gdf.assign(name='Mexico')[keep_cols + ['adm1']]\n",
        "\n",
        "admins = mex_gdf[['adm1']].drop_duplicates()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JzbskJfSXAaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Mexico training data\n",
        "mex_train = pd.DataFrame(gdf_lab[gdf_lab['name'] == 'Mexico'].drop('geometry', axis=1))\n",
        "\n",
        "np.random.seed(123)\n",
        "mex_train = mex_train.sample(frac=1).reset_index(drop=True)\n",
        "mex_train.loc[mex_train.index > int(len(mex_train) * 0.7), 'subset'] = 'validation'\n",
        "mex_train.loc[mex_train.index > int(len(mex_train) * 0.9), 'subset'] = 'testing'\n",
        "\n",
        "# mex_train = pd.concat([mex_train, filtered[filtered['inc5'] == 1]])\n",
        "print(len(mex_train))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Pad6MDYuOQYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6MRJozX3dit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bagging"
      ],
      "metadata": {
        "id": "PLzrF5Zf3RlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get train/test helper\n",
        "def get_train_test(fold, use_global=False, use_pc5=False):\n",
        "    np.random.seed(fold + 1)\n",
        "    fold_admins = admins.sample(frac=1, replace=True)\n",
        "    train_fold = mex_gdf.merge(fold_admins)\n",
        "    if use_global:\n",
        "        train_fold = pd.concat([train_fold, gdf_lab])\n",
        "    if use_pc5:\n",
        "        assert use_global == False\n",
        "        train_fold = pd.concat([train_fold, filtered.loc[filtered['inc5'] == 1, keep_cols]])\n",
        "    test_fold = pd.concat([mex_gdf, train_fold]).drop_duplicates(subset=['lat', 'lon'], keep=False)\n",
        "    return train_fold, test_fold\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rHJ01QFDYDV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make data loaders helper\n",
        "def make_data_loaders(train_fold, val_fold):\n",
        "    train_fold[label_col] = (train_fold[label_col] > 0.5).astype(int)\n",
        "    val_fold[label_col] = (val_fold[label_col] > 0.5).astype(int)\n",
        "\n",
        "    train_df = upsample_df(train_fold, label_col, upsample_minority_ratio)\n",
        "\n",
        "    x_train, y_train = get_x_y(train_df, label_col, start_month, input_months)\n",
        "    x_val, y_val = get_x_y(val_fold, label_col, start_month, input_months)\n",
        "\n",
        "    # Convert to tensors\n",
        "    train_data = PyTorchDataset(x=x_train, y=y_train)\n",
        "    val_data = PyTorchDataset(x=x_val, y=y_val)\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_data, train_dataloader, val_data, val_dataloader\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mZ6S5PtIZI3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Init model helper\n",
        "def init_model(train_data):\n",
        "\n",
        "    num_timesteps, num_bands = train_data[0][0].shape\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    class Model(torch.nn.Module):\n",
        "        def __init__(self, normalization_vals=BANDS_MAX):\n",
        "            super().__init__()\n",
        "            self.model = TransformerModel(c_in=num_bands, c_out=1)\n",
        "            self.normalization_vals = torch.tensor(normalization_vals)\n",
        "\n",
        "        def forward(self, x):\n",
        "            with torch.no_grad():\n",
        "                x = x / self.normalization_vals\n",
        "                x = x.transpose(2, 1)\n",
        "            x = self.model(x).squeeze(dim=1)\n",
        "            x = torch.sigmoid(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "    model = Model().to(device)\n",
        "    params_to_update = model.parameters()\n",
        "    optimizer = torch.optim.Adam(params_to_update, lr=lr)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    return model, device, optimizer, criterion\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8KCjgcByZI09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train model\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def train_model(model, device, optimizer, criterion,\n",
        "                train_data, train_dataloader, val_data, val_dataloader):\n",
        "\n",
        "    lowest_validation_loss = None\n",
        "    metrics = defaultdict(list)\n",
        "    train_batches = 1 + len(train_data) // batch_size\n",
        "    val_batches = 1 + len(val_data) // batch_size\n",
        "\n",
        "    with tqdm(range(num_epochs), desc=\"Epoch\") as tqdm_epoch:\n",
        "        for epoch in tqdm_epoch:\n",
        "\n",
        "            # ------------------------ Training ----------------------------------------\n",
        "            total_train_loss = 0.0\n",
        "            model.train()\n",
        "            for x in tqdm(\n",
        "                train_dataloader,\n",
        "                total=train_batches,\n",
        "                desc=\"Train\",\n",
        "                leave=False,\n",
        "                disable=IN_COLAB,\n",
        "            ):\n",
        "                inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Get model outputs and calculate loss\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_train_loss += loss.item() * len(inputs)\n",
        "\n",
        "            # ------------------------ Validation --------------------------------------\n",
        "            total_val_loss = 0.0\n",
        "            y_true = []\n",
        "            y_score = []\n",
        "            y_pred = []\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for x in tqdm(\n",
        "                    val_dataloader,\n",
        "                    total=val_batches,\n",
        "                    desc=\"Validate\",\n",
        "                    leave=False,\n",
        "                    disable=IN_COLAB,\n",
        "                ):\n",
        "                    inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    total_val_loss += loss.item() * len(inputs)\n",
        "\n",
        "                    y_true += labels.tolist()\n",
        "                    y_score += outputs.tolist()\n",
        "                    y_pred += (outputs > 0.5).long().tolist()\n",
        "\n",
        "            # ------------------------ Metrics + Logging -------------------------------\n",
        "            train_loss = total_train_loss / len(train_data)\n",
        "            val_loss = total_val_loss / len(val_data)\n",
        "\n",
        "            if lowest_validation_loss is None or val_loss < lowest_validation_loss:\n",
        "                lowest_validation_loss = val_loss\n",
        "\n",
        "            metrics['accuracy'].append(accuracy_score(y_true, y_pred))\n",
        "            metrics['f1'].append(f1_score(y_true, y_pred))\n",
        "            metrics['precision'].append(precision_score(y_true, y_pred))\n",
        "            metrics['recall'].append(recall_score(y_true, y_pred))\n",
        "            metrics['roc_auc'].append(roc_auc_score(y_true, y_score))\n",
        "            metrics['train_loss'].append(train_loss)\n",
        "            metrics['val_loss'].append(val_loss)\n",
        "\n",
        "            tqdm_epoch.set_postfix(loss=val_loss)\n",
        "            # print(epoch, round(train_loss, 3), round(val_loss, 3),\n",
        "            #       round(metrics['precision'][-1], 3), round(metrics['recall'][-1], 3))\n",
        "\n",
        "        return pd.DataFrame(metrics), y_pred\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CZ6lsmEBa8Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "seh_dyrpd9LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bagging loop\n",
        "N_FOLDS = 20\n",
        "use_global, use_pc5 = False, True\n",
        "dir = '/content/bagging_pc5'\n",
        "! mkdir $dir\n",
        "\n",
        "for fold in range(N_FOLDS):\n",
        "    train_df, val_df = get_train_test(fold, use_global=use_global, use_pc5=use_pc5)\n",
        "    print(len(train_df))\n",
        "    train_data, train_dataloader, val_data, val_dataloader = make_data_loaders(train_df, val_df)\n",
        "    model, device, optimizer, criterion = init_model(train_data)\n",
        "    metrics, preds = train_model(\n",
        "        model, device, optimizer, criterion, train_data, train_dataloader, val_data, val_dataloader)\n",
        "\n",
        "    val_df.drop('eo_data', axis=1).assign(pred_class=preds, fold=fold).to_csv(\n",
        "        f'{dir}/preds{fold}.csv', index=False)\n",
        "    metrics.assign(fold=0, iter=[x for x in range(num_epochs)]).to_csv(\n",
        "        f'{dir}/metrics{fold}.csv', index=False)\n",
        "\n",
        "    print('*' * 20, f'fold {fold} / {N_FOLDS} complete', '*' * 20)\n"
      ],
      "metadata": {
        "id": "PclDtjGka8Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GODLZpZxc5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in results\n",
        "# ! unzip /content/bagging_mex.zip\n",
        "# ! mv bagging_mex /content\n",
        "folder = 'bagging_pc5'\n",
        "\n",
        "metrics = pd.concat([pd.read_csv(f'/content/{folder}/metrics{i}.csv') for i in range(N_FOLDS)])\n",
        "preds = pd.concat([pd.read_csv(f'/content/{folder}/preds{i}.csv') for i in range(N_FOLDS)])\n",
        "\n",
        "preds_agg = preds.groupby(['lon', 'lat', 'adm1'])[['class_probability', 'pred_class']].mean().reset_index()\n",
        "metrics = metrics.groupby('iter').mean().reset_index()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rdO6BCd6a8P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot results\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly import subplots\n",
        "\n",
        "fig = plotly.subplots.make_subplots(rows=1, cols=2)\n",
        "\n",
        "x = [x for x in range(len(metrics))]\n",
        "fig.add_trace(go.Scatter(name='Train Loss', x=x, y=metrics['train_loss'], line_color='cornflowerblue'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(name='Val Loss', x=x, y=metrics['val_loss'], line_color='orange'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(name='Accuracy', x=x, y=metrics['accuracy'], line_color='blue'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='F1', x=x, y=metrics['f1'], line_color='green'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='Precision', x=x, y=metrics['precision'], line_color='purple'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='Recall', x=x, y=metrics['recall'], line_color='red'), row=1, col=2)\n",
        "\n",
        "\n",
        "fig.update_layout(height=500, width=1200)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T699jIKVhpII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tabular results\n",
        "preds_agg = preds.groupby(['lon', 'lat', 'adm1'])[['pred_class', 'class_probability']].mean().reset_index()\n",
        "preds_agg['pred_class'] = np.round(preds_agg['pred_class']).apply(int)\n",
        "preds_agg['class_probability'] = np.round(preds_agg['class_probability']).apply(int)\n",
        "y_true, y_pred = preds_agg['class_probability'], preds_agg['pred_class']\n",
        "\n",
        "print('accuracy', round(accuracy_score(y_true, y_pred), 3))\n",
        "print('f1', round(f1_score(y_true, y_pred), 3))\n",
        "print('precision', round(precision_score(y_true, y_pred), 3))\n",
        "print('recall', round(recall_score(y_true, y_pred), 3))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mdYqKAM8hpFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Map results\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "sns.set_style('white')\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=[12, 7])\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "for i in range(2):\n",
        "    mex_adm1.plot(edgecolor='darkgray', color='none', ax=ax[i])\n",
        "    ax[i].set_axis_off()\n",
        "\n",
        "plot_preds.plot(column='class_probability', cmap='bwr', markersize=5, ax=ax[0])\n",
        "plot_preds.plot(column='pred_class', cmap='bwr', markersize=5, ax=ax[1])\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yOvRjnKBhpC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFbMwcU7hpAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment model code"
      ],
      "metadata": {
        "id": "p6KPYzL2Z9Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is basically redundant with the bagging code but makes it a bit easier to experimentally train a single model"
      ],
      "metadata": {
        "id": "M1hhe85332fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataloaders\n",
        "mex_train[label_col] = (mex_train[label_col] > 0.5).astype(int)\n",
        "train_df = mex_train[mex_train[SUBSET] == \"training\"]\n",
        "\n",
        "train_df = upsample_df(train_df, label_col, upsample_minority_ratio)\n",
        "val_df = mex_train[mex_train[SUBSET] == \"validation\"]\n",
        "x_train, y_train = get_x_y(train_df, label_col, start_month, input_months)\n",
        "x_val, y_val = get_x_y(val_df, label_col, start_month, input_months)\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = PyTorchDataset(x=x_train, y=y_train)\n",
        "val_data = PyTorchDataset(x=x_val, y=y_val)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Em1-Rb4ONlTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Init model\n",
        "num_timesteps, num_bands = train_data[0][0].shape\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, normalization_vals=BANDS_MAX):\n",
        "        super().__init__()\n",
        "        self.model = TransformerModel(c_in=num_bands, c_out=1)\n",
        "        self.normalization_vals = torch.tensor(normalization_vals)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            x = x / self.normalization_vals\n",
        "            x = x.transpose(2, 1)\n",
        "        x = self.model(x).squeeze(dim=1)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model().to(device)\n",
        "\n",
        "# ------------ Model hyperparameters -------------------------------------\n",
        "params_to_update = model.parameters()\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=lr)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "if model_name == \"\":\n",
        "    model_name = generate_model_name(val_df=val_df, start_month=start_month)\n",
        "\n",
        "lowest_validation_loss = None\n",
        "metrics = {}\n",
        "train_batches = 1 + len(train_data) // batch_size\n",
        "val_batches = 1 + len(val_data) // batch_size"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pVYiqXAeRKYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train model\n",
        "\n",
        "lowest_validation_loss = None\n",
        "metrics = {}\n",
        "train_batches = 1 + len(train_data) // batch_size\n",
        "val_batches = 1 + len(val_data) // batch_size\n",
        "\n",
        "train_loss_arr, val_loss_arr = [], []\n",
        "acc_arr, f1_arr, recall_arr, prec_arr = [], [], [], []\n",
        "\n",
        "with tqdm(range(num_epochs), desc=\"Epoch\") as tqdm_epoch:\n",
        "    for epoch in tqdm_epoch:\n",
        "\n",
        "        # ------------------------ Training ----------------------------------------\n",
        "        total_train_loss = 0.0\n",
        "        model.train()\n",
        "        for x in tqdm(\n",
        "            train_dataloader,\n",
        "            total=train_batches,\n",
        "            desc=\"Train\",\n",
        "            leave=False,\n",
        "            disable=IN_COLAB,\n",
        "        ):\n",
        "            inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get model outputs and calculate loss\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item() * len(inputs)\n",
        "\n",
        "        # ------------------------ Validation --------------------------------------\n",
        "        total_val_loss = 0.0\n",
        "        y_true = []\n",
        "        y_score = []\n",
        "        y_pred = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x in tqdm(\n",
        "                val_dataloader,\n",
        "                total=val_batches,\n",
        "                desc=\"Validate\",\n",
        "                leave=False,\n",
        "                disable=IN_COLAB,\n",
        "            ):\n",
        "                inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "                # Get model outputs and calculate loss\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_val_loss += loss.item() * len(inputs)\n",
        "\n",
        "                y_true += labels.tolist()\n",
        "                y_score += outputs.tolist()\n",
        "                y_pred += (outputs > 0.5).long().tolist()\n",
        "\n",
        "        # ------------------------ Metrics + Logging -------------------------------\n",
        "        train_loss = total_train_loss / len(train_data)\n",
        "        val_loss = total_val_loss / len(val_data)\n",
        "\n",
        "        if lowest_validation_loss is None or val_loss < lowest_validation_loss:\n",
        "            lowest_validation_loss = val_loss\n",
        "\n",
        "        metrics = {\n",
        "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "            \"f1\": f1_score(y_true, y_pred),\n",
        "            \"precision\": precision_score(y_true, y_pred),\n",
        "            \"recall\": recall_score(y_true, y_pred),\n",
        "            \"roc_auc\": roc_auc_score(y_true, y_score),\n",
        "        }\n",
        "        metrics = {k: round(float(v), 4) for k, v in metrics.items()}\n",
        "        print(round(train_loss, 3), round(val_loss, 3), metrics)\n",
        "\n",
        "        train_loss_arr.append(train_loss)\n",
        "        val_loss_arr.append(val_loss)\n",
        "        acc_arr.append(metrics['accuracy'])\n",
        "        f1_arr.append(metrics['f1'])\n",
        "        recall_arr.append(metrics['recall'])\n",
        "        prec_arr.append(metrics['precision'])\n",
        "\n",
        "        tqdm_epoch.set_postfix(loss=val_loss)\n",
        "\n",
        "        # ------------------------ Model saving --------------------------\n",
        "        if lowest_validation_loss == val_loss:\n",
        "            # Some models in tsai need to be modified to be TorchScriptable\n",
        "            # https://github.com/timeseriesAI/tsai/issues/561\n",
        "            sm = torch.jit.script(model)\n",
        "            model_path = model_path_from_name(model_name=model_name)\n",
        "            if model_path.exists():\n",
        "                model_path.unlink()\n",
        "            else:\n",
        "                model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            sm.save(str(model_path))\n",
        "\n"
      ],
      "metadata": {
        "id": "B9_LYVQNKGjS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot results\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly import subplots\n",
        "\n",
        "fig = plotly.subplots.make_subplots(rows=1, cols=2)\n",
        "\n",
        "x = [x for x in range(num_epochs)]\n",
        "fig.add_trace(go.Scatter(name='Train Loss', x=x, y=train_loss_arr, line_color='cornflowerblue'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(name='Val Loss', x=x, y=val_loss_arr, line_color='orange'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(name='Accuracy', x=x, y=acc_arr, line_color='blue'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='F1', x=x, y=f1_arr, line_color='green'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='Precision', x=x, y=prec_arr, line_color='purple'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='Recall', x=x, y=recall_arr, line_color='red'), row=1, col=2)\n",
        "\n",
        "fig.update_layout(height=500, width=1200)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a4Jc0wabhQuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MODEL_NAME={model_name}\")\n",
        "print(model_path_from_name(model_name=model_name))\n",
        "print(yaml.dump(metrics, allow_unicode=True, default_flow_style=False))\n"
      ],
      "metadata": {
        "id": "EjykHXVIKGg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5hRKrCfhQps"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Bnb3NmfxSQyo",
        "ImE0eM9vS7aD",
        "HaMZaR_5IavT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd96feeca8c75643d28e6472f2b0778c141660d21a3db17f7d03cb9dc5057e55"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}