{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/issmythe/ccai_crop_mapping/blob/main/tutorial_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ2Sgm2z9Opu"
      },
      "source": [
        "# OpenMapFlow Tutorial\n",
        "\n",
        "### Sections\n",
        "1. Installing OpenMapFlow\n",
        "2. Exploring labeled earth observation data\n",
        "3. Training a model\n",
        "4. Doing inference over small region\n",
        "5. Deploying of best model\n",
        "\n",
        "### Prerequisites:\n",
        "- Github account\n",
        "- Github access token (obtained [here](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token))\n",
        "- Forked OpenMapFlow repository\n",
        "- Basic Python knowledge  \n",
        "\n",
        "### Editable Google Doc for Q&A:\n",
        "https://docs.google.com/document/d/1Kp6MphER1G5tdLYeAzl4n19S10TweIxiYT64rXsjKm4/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnb3NmfxSQyo"
      },
      "source": [
        "## 1. Clone Github repo and install OpenMapFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug7hI6g7Wu3f"
      },
      "outputs": [],
      "source": [
        "!pip install \"ipywidgets>=7,<8\" -q # https://github.com/googlecolab/colabtools/issues/3020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxD8Zbzr8lyu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Git credentials\n",
        "from ipywidgets import HTML, Password, Text, Textarea, VBox\n",
        "inputs = [\n",
        "      Password(description=\"Github Token:\"),\n",
        "      Text(description='Github Email:'),\n",
        "      Text(description='Github User:'),\n",
        "]\n",
        "VBox(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16CaMAzNxokf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone directory\n",
        "token = inputs[0].value\n",
        "email = inputs[1].value\n",
        "username = inputs[2].value\n",
        "\n",
        "github_url_input = Textarea(value=f'https://github.com/{username}/openmapflow.git')\n",
        "VBox([HTML(value=\"<b>Github Clone URL</b>\"), github_url_input])\n",
        "\n",
        "! git clone -q https://$token@github.com/nasaharvest/openmapflow.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mg8UBJ_HP6Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdFlxgOX9Mit",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Config\n",
        "from pathlib import Path\n",
        "\n",
        "github_url = github_url_input.value\n",
        "project_name = \"crop-mask-example\" # maize-example\n",
        "country_name = \"Togo\" # Kenya\n",
        "\n",
        "for input_value in [token, email, username, github_url]:\n",
        "  if input_value.strip() == \"\":\n",
        "    raise ValueError(\"Found input with blank value.\")\n",
        "\n",
        "path_to_project = f\"{Path(github_url).stem}/{project_name}\"\n",
        "\n",
        "!git config --global user.email $username\n",
        "!git config --global user.name $email\n",
        "!git clone {github_url.replace(\"https://\", f\"https://{username}:{token}@\")}\n",
        "\n",
        "%cd {path_to_project}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installs\n",
        "!pip install openmapflow[all] -q &> /dev/null\n",
        "!pip install dvc[gs] cmocean -q &> /dev/null"
      ],
      "metadata": {
        "id": "AK7eXnZEXb4_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download GDAL\n",
        "%%shell\n",
        "GDAL_VERSION=\"3.6.4+dfsg-1~jammy0\"\n",
        "add-apt-repository -y ppa:ubuntugis/ubuntugis-unstable &> /dev/null\n",
        "apt-get -qq update &> /dev/null\n",
        "apt-get -qq install python3-gdal=$GDAL_VERSION gdal-bin=$GDAL_VERSION libgdal-dev=$GDAL_VERSION &> /dev/null"
      ],
      "metadata": {
        "id": "NGv4CE0zXLxj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckKKdRZW-06Q"
      },
      "outputs": [],
      "source": [
        "# CLI\n",
        "!openmapflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT5oQHkeBDIg"
      },
      "source": [
        "## 2. Exploring labeled earth observation data ðŸ›°ï¸\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "5YmEZeoxG77r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhzRYzMNOiNV"
      },
      "outputs": [],
      "source": [
        "# A Google Cloud Account is required to access the data\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR9cC92EIKC6"
      },
      "outputs": [],
      "source": [
        "# Pull in data already available\n",
        "! dvc pull &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tc1Hblc-7vf"
      },
      "outputs": [],
      "source": [
        "# See report of data already available\n",
        "! openmapflow datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzHcMQV1S0pS"
      },
      "source": [
        "### Exploring labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swxLRI8B_4iY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports + read data\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from datasets import datasets, label_col\n",
        "from openmapflow.constants import LAT, LON, DATASET, SUBSET\n",
        "\n",
        "df = pd.concat([d.load_df(to_np=True) for d in datasets[:1]]) # Global only"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObzeO-2EHWEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zoi8t0A0YfsM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Convert pandas dataframe to geopandas dataframe\n",
        "gdf = gpd.GeoDataFrame(df)\n",
        "gdf[\"geometry\"] = [Point(xy) for xy in zip(gdf[LON], gdf[LAT])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLd5xf29ZHdm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plot labels\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "ax = world.plot(figsize=(20,20), facecolor=\"lightgray\")\n",
        "ax.set_title(\"Label Locations\")\n",
        "ax.axis('off')\n",
        "gdf.plot(\n",
        "    ax=ax,\n",
        "    marker='o',\n",
        "    categorical=True,\n",
        "    markersize=1,\n",
        "    column=DATASET,\n",
        "    legend=True,\n",
        "    legend_kwds={'loc': 'lower left'});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSzLeUIxPp1i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTxkzHh6BreD"
      },
      "source": [
        "## 3. Train a model ðŸ‹ï¸â€â™‚ï¸"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "from openmapflow import train_utils\n",
        "importlib.reload(train_utils)\n"
      ],
      "metadata": {
        "id": "DLL0rB_daNcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import torch\n",
        "import yaml\n",
        "from datasets import datasets, label_col\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "from tsai.models.TransformerModel import TransformerModel\n",
        "\n",
        "from openmapflow.bands import BANDS_MAX\n",
        "from openmapflow.constants import SUBSET\n",
        "from openmapflow.pytorch_dataset import PyTorchDataset\n",
        "from openmapflow.train_utils import (\n",
        "    generate_model_name,\n",
        "    get_x_y,\n",
        "    model_path_from_name,\n",
        "    upsample_df,\n",
        ")\n",
        "from openmapflow.utils import tqdm\n",
        "\n",
        "try:\n",
        "    import google.colab  # noqa\n",
        "\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)  # TorchScript throws excessive warnings"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z6qY4yVbNpBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Overwrite get_x_y\n",
        "from typing import List, Tuple\n",
        "from openmapflow.constants import CLASS_PROB, EO_DATA, MONTHS\n",
        "from openmapflow.utils import str_to_np\n",
        "\n",
        "def get_x_y(\n",
        "    df: pd.DataFrame,\n",
        "    label_col: str = CLASS_PROB,\n",
        "    start_month: str = \"February\",\n",
        "    input_months: int = 12,\n",
        ") -> Tuple[List[np.ndarray], List[float]]:\n",
        "    \"\"\"Get the X and y data from a dataframe.\"\"\"\n",
        "    i = MONTHS.index(start_month)\n",
        "\n",
        "    def to_numpy(x: str):\n",
        "        if type(x) == str:\n",
        "            x = str_to_np(x)\n",
        "        return x[i : i + input_months, :]  # noqa\n",
        "\n",
        "    tqdm.pandas()\n",
        "    return df[EO_DATA].progress_apply(to_numpy).to_list(), df[label_col].to_list()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N4vKNSpaQkTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'm1'\n",
        "\n",
        "start_month = 'February'\n",
        "input_months = 12\n",
        "batch_size = 32\n",
        "upsample_minority_ratio = 0.5\n",
        "lr = 0.0001\n",
        "num_epochs = 100\n"
      ],
      "metadata": {
        "id": "0AuF_K7ENufu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get country boundaries\n",
        "countries = gpd.read_file('/content/world_adm.geojson')\n",
        "gdf_lab = countries[['name', 'geometry']].sjoin(gdf, how='inner', predicate='intersects')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EJEzAa6FDxFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Mexico training data\n",
        "mex_train = pd.DataFrame(gdf_lab[gdf_lab['name'] == 'Mexico'].drop('geometry', axis=1))\n",
        "\n",
        "np.random.seed(123)\n",
        "mex_train = mex_train.sample(frac=1).reset_index(drop=True)\n",
        "mex_train.loc[mex_train.index > int(len(mex_train) * 0.7), 'subset'] = 'validation'\n",
        "mex_train.loc[mex_train.index > int(len(mex_train) * 0.9), 'subset'] = 'testing'\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Pad6MDYuOQYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmjayOBfQUdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bb2iXncrdte5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataloaders\n",
        "mex_train[label_col] = (mex_train[label_col] > 0.5).astype(int)\n",
        "train_df = mex_train[mex_train[SUBSET] == \"training\"]\n",
        "\n",
        "train_df = upsample_df(train_df, label_col, upsample_minority_ratio)\n",
        "val_df = mex_train[mex_train[SUBSET] == \"validation\"]\n",
        "x_train, y_train = get_x_y(train_df, label_col, start_month, input_months)\n",
        "x_val, y_val = get_x_y(val_df, label_col, start_month, input_months)\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = PyTorchDataset(x=x_train, y=y_train)\n",
        "val_data = PyTorchDataset(x=x_val, y=y_val)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Em1-Rb4ONlTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Init model\n",
        "num_timesteps, num_bands = train_data[0][0].shape\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, normalization_vals=BANDS_MAX):\n",
        "        super().__init__()\n",
        "        self.model = TransformerModel(c_in=num_bands, c_out=1)\n",
        "        self.normalization_vals = torch.tensor(normalization_vals)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            x = x / self.normalization_vals\n",
        "            x = x.transpose(2, 1)\n",
        "        x = self.model(x).squeeze(dim=1)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model().to(device)\n",
        "\n",
        "# ------------ Model hyperparameters -------------------------------------\n",
        "params_to_update = model.parameters()\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=lr)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "if model_name == \"\":\n",
        "    model_name = generate_model_name(val_df=val_df, start_month=start_month)\n",
        "\n",
        "lowest_validation_loss = None\n",
        "metrics = {}\n",
        "train_batches = 1 + len(train_data) // batch_size\n",
        "val_batches = 1 + len(val_data) // batch_size"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pVYiqXAeRKYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train model\n",
        "train_loss_arr, val_loss_arr = [], []\n",
        "acc_arr, f1_arr, recall_arr, prec_arr = [], [], [], []\n",
        "\n",
        "with tqdm(range(num_epochs), desc=\"Epoch\") as tqdm_epoch:\n",
        "    for epoch in tqdm_epoch:\n",
        "\n",
        "        # ------------------------ Training ----------------------------------------\n",
        "        total_train_loss = 0.0\n",
        "        model.train()\n",
        "        for x in tqdm(\n",
        "            train_dataloader,\n",
        "            total=train_batches,\n",
        "            desc=\"Train\",\n",
        "            leave=False,\n",
        "            disable=IN_COLAB,\n",
        "        ):\n",
        "            inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get model outputs and calculate loss\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item() * len(inputs)\n",
        "\n",
        "        # ------------------------ Validation --------------------------------------\n",
        "        total_val_loss = 0.0\n",
        "        y_true = []\n",
        "        y_score = []\n",
        "        y_pred = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x in tqdm(\n",
        "                val_dataloader,\n",
        "                total=val_batches,\n",
        "                desc=\"Validate\",\n",
        "                leave=False,\n",
        "                disable=IN_COLAB,\n",
        "            ):\n",
        "                inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "                # Get model outputs and calculate loss\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_val_loss += loss.item() * len(inputs)\n",
        "\n",
        "                y_true += labels.tolist()\n",
        "                y_score += outputs.tolist()\n",
        "                y_pred += (outputs > 0.5).long().tolist()\n",
        "\n",
        "        # ------------------------ Metrics + Logging -------------------------------\n",
        "        train_loss = total_train_loss / len(train_data)\n",
        "        val_loss = total_val_loss / len(val_data)\n",
        "\n",
        "        if lowest_validation_loss is None or val_loss < lowest_validation_loss:\n",
        "            lowest_validation_loss = val_loss\n",
        "\n",
        "        metrics = {\n",
        "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "            \"f1\": f1_score(y_true, y_pred),\n",
        "            \"precision\": precision_score(y_true, y_pred),\n",
        "            \"recall\": recall_score(y_true, y_pred),\n",
        "            \"roc_auc\": roc_auc_score(y_true, y_score),\n",
        "        }\n",
        "        metrics = {k: round(float(v), 4) for k, v in metrics.items()}\n",
        "        print(round(train_loss, 3), round(val_loss, 3), metrics)\n",
        "\n",
        "        train_loss_arr.append(train_loss)\n",
        "        val_loss_arr.append(val_loss)\n",
        "        acc_arr.append(metrics['accuracy'])\n",
        "        f1_arr.append(metrics['f1'])\n",
        "        recall_arr.append(metrics['recall'])\n",
        "        prec_arr.append(metrics['precision'])\n",
        "\n",
        "        tqdm_epoch.set_postfix(loss=val_loss)\n",
        "\n",
        "        # ------------------------ Model saving --------------------------\n",
        "        if lowest_validation_loss == val_loss:\n",
        "            # Some models in tsai need to be modified to be TorchScriptable\n",
        "            # https://github.com/timeseriesAI/tsai/issues/561\n",
        "            sm = torch.jit.script(model)\n",
        "            model_path = model_path_from_name(model_name=model_name)\n",
        "            if model_path.exists():\n",
        "                model_path.unlink()\n",
        "            else:\n",
        "                model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            sm.save(str(model_path))\n",
        "\n"
      ],
      "metadata": {
        "id": "B9_LYVQNKGjS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot results\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly import subplots\n",
        "\n",
        "fig = plotly.subplots.make_subplots(rows=1, cols=2)\n",
        "\n",
        "x = [x for x in range(num_epochs)]\n",
        "fig.add_trace(go.Scatter(name='Train Loss', x=x, y=train_loss_arr, line_color='cornflowerblue'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(name='Val Loss', x=x, y=val_loss_arr, line_color='orange'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(name='Accuracy', x=x, y=acc_arr, line_color='blue'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='F1', x=x, y=f1_arr, line_color='green'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='Precision', x=x, y=prec_arr, line_color='purple'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(name='Recall', x=x, y=recall_arr, line_color='red'), row=1, col=2)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "a4Jc0wabhQuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MODEL_NAME={model_name}\")\n",
        "print(model_path_from_name(model_name=model_name))\n",
        "print(yaml.dump(metrics, allow_unicode=True, default_flow_style=False))\n"
      ],
      "metadata": {
        "id": "EjykHXVIKGg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5hRKrCfhQps"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Bnb3NmfxSQyo",
        "ImE0eM9vS7aD",
        "HaMZaR_5IavT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd96feeca8c75643d28e6472f2b0778c141660d21a3db17f7d03cb9dc5057e55"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}